
# **Deals-Notifier_LLM**

## ğŸš€ **Project Overview**
**Deals-Notifier_LLM** is an AI-driven system designed to scrape, analyze, and notify users of the best Amazon deals in real-time. By leveraging web scraping, a Chroma database, fine-tuned language models (LLMs), and modular agents, the system ensures timely notifications about valuable deals.

---

## ğŸ“‚ **Repository Structure**
```
Deals-Notifier_LLM/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ deals.py                  # Defines the ScrapedDeal class and related functions
â”‚   â”œâ”€â”€ ensemble_agent.py         # Estimates deal prices using AI models
â”‚   â”œâ”€â”€ frontier_agent.py         # RAG-based deal pricer
â”‚   â”œâ”€â”€ llama.py                  # LLaMA model integration
â”‚   â”œâ”€â”€ messaging_agent.py        # Sends notifications via Pushover
â”‚   â”œâ”€â”€ planning_agent.py         # Coordinates agent activities
â”‚   â”œâ”€â”€ pricer_service.py         # Service for pricing deals
â”‚   â”œâ”€â”€ scanner_agent.py          # Scrapes deals from RSS feeds
â”‚   â””â”€â”€ testing.py                # Contains test cases for agents
â”œâ”€â”€ Database_Creation.ipynb       # Creates the Chroma database
â”œâ”€â”€ Database_Visual_3D.ipynb      # Visualizes the database in 3D
â”œâ”€â”€ Ensemble_Creation.ipynb       # Builds and trains the ensemble model
â”œâ”€â”€ Final_Run.ipynb               # Executes the full pipeline
â”œâ”€â”€ Model_Upload.ipynb            # Deploys fine-tuned models
â”œâ”€â”€ Similar_Finder.ipynb          # Finds similar products using sentence-transformers
â”œâ”€â”€ deal_agent_framework.py       # Framework for deal agents
â”œâ”€â”€ price_is_right.py             # Main script to run the entire system
â”œâ”€â”€ price_is_right_final.py       # Final version of the main script
â”œâ”€â”€ pricer_ephemeral.py           # Ephemeral pricing service
â”œâ”€â”€ pricer_service2.py            # Alternative pricing service implementation
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ environment.yml               # Conda environment configuration
â”œâ”€â”€ LICENSE                       # License information
â”œâ”€â”€ README.md                     # Project documentation
â””â”€â”€ requirements.txt              # Required Python packages
```

---

## ğŸ› ï¸ **Key Features**
- **Real-Time Scraping**: Utilizes `scanner_agent.py` to fetch deals from RSS feeds.
- **AI-Powered Price Estimation**: Employs an ensemble of fine-tuned LLMs and machine learning models in `ensemble_agent.py`.
- **Notification System**: Sends real-time deal alerts via Pushover using `messaging_agent.py`.
- **Modular Agent Framework**: Coordinates various agents through `planning_agent.py` for efficient workflow management.

---

## ğŸ’» **Getting Started**

### **Prerequisites**
- **Python 3.9** or higher.
- Required Python libraries (detailed in `requirements.txt`).

### **Setup Instructions**
1. **Clone the Repository**
   ```bash
   git clone https://github.com/KaushikML/Deals-Notifier_LLM.git
   cd Deals-Notifier_LLM
   ```

2. **Set Up the Environment**
   - **Using Conda**:
     ```bash
     conda env create -f environment.yml
     conda activate deals-notifier
     ```
   - **Using Virtual Environment**:
     ```bash
     python3 -m venv env
     source env/bin/activate  # On Windows, use `env\Scriptsctivate`
     pip install -r requirements.txt
     ```

3. **Configure API Keys**
   - Create a `.env` file in the root directory with the following content:
     ```
     OPENAI_API_KEY=your_openai_api_key
     DEEPSEEK_API_KEY=your_deepseek_api_key
     HUGGINGFACE_API_KEY=your_huggingface_api_key
     PUSHOVER_USER=your_pushover_user_key
     PUSHOVER_TOKEN=your_pushover_api_token
     ```

---

## ğŸš€ **Execution Steps**

1. **Model Deployment**
   - **Notebook**: `Model_Upload.ipynb`
   - **Purpose**: Deploy fine-tuned models, including GPT-4o Mini, LLaMA 3.1, and the Random Forest Regressor.

2. **Database Creation**
   - **Notebook**: `Database_Creation.ipynb`
   - **Purpose**: Create the Chroma database with over 400,000 product data points.

3. **Ensemble Model Creation**
   - **Notebook**: `Ensemble_Creation.ipynb`
   - **Purpose**: Set up and fine-tune the ensemble model, combining predictions from various AI models.

4. **Similar Product Finder**
   - **Notebook**: `Similar_Finder.ipynb`
   - **Purpose**: Implement the sentence-transformer model (`all-MiniLM-L6-v2`) to find similar products based on descriptions.

5. **Final Execution**
   - **Notebook**: `Final_Run.ipynb`
   - **Purpose**: Execute the complete pipeline, including:
     - Scraping deals.
     - Analyzing and estimating prices.
     - Sending notifications to users via Pushover.

---

## ğŸ› ï¸ **Technology Stack**
- **Programming Languages**: Python
- **Machine Learning Frameworks**: Scikit-learn
- **Large Language Models**: GPT-4o Mini, LLaMA 3.1
- **Database**: Chroma for vector similarity search
- **Web Scraping**: BeautifulSoup
- **Deployment**: Modal
- **Notification System**: Pushover

---

## ğŸ¤ **Contributing**
Contributions are welcome! Please follow these steps:
1. **Fork the Repository**
2. **Create a New Branch**
   ```bash
   git checkout -b feature-name
   ```
3. **Commit Your Changes**
   ```bash
   git commit -m 'Add a feature'
   ```
4. **Push to the Branch**
   ```bash
   git push origin feature-name
   ```
5. **Submit a Pull Request**

---

## ğŸ“ **License**
This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.

---

## ğŸ“¬ **Contact**
For questions, suggestions, or collaboration opportunities, feel free to open an issue in this repository.

